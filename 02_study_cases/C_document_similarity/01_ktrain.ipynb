{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["USE_NMF = True\n","N_NEIGHBORS = 20"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import re\n","import random\n","import ktrain\n","import pandas as pd\n","from sklearn.metrics import classification_report\n","random.seed(42)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def clean(doc):\n","    doc = str(doc).lower()\n","    doc = re.sub('[^A-Za-z\\ ]', ' ', doc)\n","    doc = re.sub(r'\\b\\w{0,1}\\b', '', doc)\n","    doc = re.sub('\\s{2,}', ' ', doc)\n","\n","    return doc\n","\n","def process_csv(path):\n","    df = pd.read_csv(path).astype(str)\n","    print(df.shape)\n","    df['Article'] = df.apply(\n","        lambda d: d['Title'] + ' ' + d['Ingredients'] + ' ' + d['Steps'], axis=1\n","    )\n","    df['Article'] = df['Article'].apply(clean)\n","    df['Label'] = 1\n","    return df[['Article', 'Label']]\n","\n","def process_json(path):\n","    df = pd.read_json(path, orient='column').astype(str)\n","    print(df.shape)\n","    df['Article'] = df['content'].apply(clean)\n","    df['Label'] = 0\n","    return df[['Article', 'Label']]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["path_train = [\n","    './dataset/recipe/dataset-ayam.csv',\n","    './dataset/recipe/dataset-ikan.csv',\n","    './dataset/recipe/dataset-kambing.csv',\n","    './dataset/recipe/dataset-sapi.csv',\n","    './dataset/recipe/dataset-udang.csv'\n","]\n","path_test = [\n","    './dataset/recipe/dataset-tahu.csv',\n","    './dataset/recipe/dataset-telur.csv',\n","    './dataset/recipe/dataset-tempe.csv',\n","    './dataset/criminality_news.json'\n","]\n","train_docs, test_docs = [], []\n","\n","for p in path_train:\n","    train_docs.append(process_csv(p))\n","X_train = pd.concat(train_docs, ignore_index=True)['Article'].tolist()\n","for p in path_test:\n","    if p[-4:] == '.csv':\n","        test_docs.append(process_csv(p))\n","    else:\n","        test_docs.append(process_json(p))\n","X_test = pd.concat(test_docs, ignore_index=True)['Article'].tolist()\n","y_test = pd.concat(test_docs, ignore_index=True)['Label'].tolist()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["with open('./dataset/id.stopwords.02.01.2016.txt') as f:\n","    stop_words = f.read().split('\\n')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ilos-vigil/Desktop/study_ktrain/.venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n","  warnings.warn('Your stop_words may be inconsistent with '\n"]}],"source":["if USE_NMF:\n","    tm = ktrain.text.get_topic_model(\n","        X_train, n_topics=5, stop_words=stop_words, \n","        min_df=25, max_df=0.5, model_type='nmf',\n","        lda_max_iter=100, n_features=10000, verbose=0\n","    )\n","else:\n","    tm = ktrain.text.get_topic_model(\n","        X_train, n_topics=5, stop_words=stop_words, \n","        min_df=25, max_df=0.5, model_type='lda', lda_mode='batch',\n","        lda_max_iter=100, n_features=10000, verbose=0\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["topic:0 | count:1925 | daging sapi kecap sdm kambing sdt manis bubuk iris\n","topic:3 | count:1827 | udang sdm tepung saus cabe saos iris telur tomat\n","topic:1 | count:1639 | ayam tepung sdm sdt bubuk telur bahan yg kecap\n","topic:2 | count:1432 | cabe jeruk salam halus santan ruas jahe rawit lembar\n","topic:4 | count:1155 | ikan cabe jeruk tomat nipis iris sdm matang tongkol\n"]}],"source":["tm.build(X_train, threshold=0.2)\n","tm.print_topics(n_words=9, show_counts=True)\n","tm.train_scorer(n_neighbors=N_NEIGHBORS)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       Resep       0.71      1.00      0.83     10751\n","      Berita       0.97      0.27      0.43      5945\n","\n","    accuracy                           0.74     16696\n","   macro avg       0.84      0.63      0.63     16696\n","weighted avg       0.81      0.74      0.69     16696\n","\n"]}],"source":["y_pred = tm.score(X_test)\n","y_pred = [1 if s >= 0 else 0 for s in y_pred]\n","print(classification_report(y_test, y_pred, target_names=['Resep', 'Berita']))"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
